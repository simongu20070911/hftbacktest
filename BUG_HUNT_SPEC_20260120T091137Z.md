# HFTBacktest Bug Hunt Spec (verbatim)

- Generated at (UTC): 2026-01-20T09:11:37.815334+00:00
- ParallelHassnes batch_id: `batch_20260120T084732Z_64624b39`
- Source runs dir: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39`

This document captures the *verbatim* `summary` text emitted by each agent run in the batch above.

---

## Completed (2026-01-20)

Batch: `batch_20260120T121548Z_1d74ae4b` (hftbacktest commit `13c7fd1`)

- [x] fix_01_depth_clear_bugs
- [x] fix_02_btree_depth_contracts
- [x] fix_03_partialfill_accounting_and_rejects
- [x] fix_04_npy_reader_robustness
- [x] fix_05_timestamp_overflow_checks

## agent_01_build_and_tests (status: failed)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_01_build_and_tests/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_a8c0a33f/final.json`

~~~~text
Commands run (with `CARGO_TARGET_DIR=.ph_target/agent_01`):
- `cargo test --workspace` (FAILED)
- `cargo test -p hftbacktest --lib` (PASS: 22 tests)
- `cargo test --workspace --lib` (PASS)

Failure cause: `cargo test --workspace` fails while compiling **examples** in `hftbacktest`.

Exact error excerpts (from `cargo test --workspace`):
- `error[E0601]: `main` function not found in crate `algo``
  -> `hftbacktest/examples/algo.rs:164:2`
- `error[E0599]: no function or associated item named `builder` found for struct `LiveBot<CH, MD>``
  -> `hftbacktest/examples/logging_order_latency.rs:14:28`
- `error[E0599]: no method named `process_recv_order2` found for struct `Local<AT, LM, MD, FM>``
  -> `hftbacktest/examples/custom_evhandling.rs:146:14`
- `error[E0599]: no method named `run` found for struct `LiveBot<CH, MD>``
  -> `hftbacktest/examples/gridtrading_live_bybit.rs:49:9`

Likely root causes:
- `hftbacktest/examples/algo.rs` is being used as a shared `mod algo;` module by other examples, but Cargo also treats it as a standalone example binary (needs `fn main()` or needs to be moved under a non-example module path, e.g. `examples/algo/mod.rs`).
- Live API drift: `hftbacktest/src/live/bot.rs` defines `LiveBotBuilder::new()`/`.build()` but no `LiveBot::builder()` and no `LiveBot::run()`. The doc example in `hftbacktest/src/live/bot.rs` also references `LiveBot::builder()`.
- Backtest processor API drift: `hftbacktest/src/backtest/proc/mod.rs` only has `process_recv_order(...)`; `process_recv_order2(...)` is not present in the crate.

Suspicious warnings noticed during builds (not failing, but likely regressions/cleanup candidates):
- `hftbacktest/src/live/bot.rs`: `modify(...)` is `todo!()` and triggers unused-arg warnings (`asset_no`, `order_id`, `price`, `qty`, `wait`).
- `collector/src/main.rs`: unused variable `handle`.
- `collector/src/*/http.rs`: multiple `fetch_symbol_list` functions are dead code.
- `connector/src/...`: several `unused_mut`/`dead_code` warnings.
~~~~

## agent_02_clippy_and_lints (status: needs_attention)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_02_clippy_and_lints/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_e89bc2e2/final.json`

~~~~text
Clippy run (with `CARGO_TARGET_DIR=".ph_target/agent_02"`) failed with build errors in examples, so the workspace was not fully linted to completion.

Command:
- `export CARGO_TARGET_DIR=".ph_target/agent_02"; cargo clippy --workspace --all-targets --all-features`

Hard failures (block clippy):
- `hftbacktest/examples/algo.rs` (example crate `algo`): error[E0601] missing `main`.
- `hftbacktest/examples/gridtrading_live_bybit.rs::prepare_live`: error[E0599] `LiveBot::run` does not exist.

Triage of findings (from `clippy.log`):
(a) Potential bug / correctness breakage
- `hftbacktest/src/live/bot.rs::LiveBot::<CH,MD>::modify` (unused args flagged by clippy) is currently `todo!()` and will panic at runtime if called; implement it (e.g., set order fields + `order.req = Status::Replaced` and send `LiveRequest::Order {..}`) or return a non-panicking error (e.g., `BotError::Custom("modify not supported".into())`).
- `connector/src/binancefutures/market_data_stream.rs::MarketDataStream` and `connector/src/binancespot/market_data_stream.rs::MarketDataStream`: `pending_depth_messages` is never read; combined with commented-out sequencing checks, this risks incorrect book state when websocket depth updates arrive out-of-order; either remove the dead field or implement the intended buffering/continuity logic.
- `hftbacktest/examples/algo.rs` being a top-level `examples/*.rs` file without `main` breaks `--all-targets`; best fix is to move it to `hftbacktest/examples/algo/mod.rs` (aux module, not an example target) so `mod algo;` still works.
- `hftbacktest/examples/gridtrading_live_bybit.rs::prepare_live`: remove/replace `hbt.run().unwrap();` since `LiveBotBuilder::build()` already registers instruments; if some “start connector” step is needed, it likely belongs outside `LiveBot` (e.g., running the `connector` process).

(b) Correctness footguns
- `collector/src/main.rs::main`: `handle` is unused because `handle.await` is commented out; errors/panics from the spawned collection task are effectively ignored; consider `select!` on `handle` vs `ctrl_c`, and abort/join on shutdown.
- `connector/src/binancespot/ordermanager.rs::OrderManager::gc` is never used; if it’s required to prevent stale order/map growth (as the doc suggests), it should be scheduled/called.

(c) Perf/alloc hotspots
- `connector/src/binancefutures/msg/rest.rs::OrderResponseResult` and multiple enums in `connector/src/binancespot/msg/stream.rs` (`MarketEventStream`, `UserEventStream`, `MarketStream`, `UserStream`) trigger `clippy::large_enum_variant`; boxing large variants (as clippy suggests) can significantly reduce enum size/copies on hot paths.

(d) Style/noise
- Examples: `clippy::unnecessary_cast`, `clippy::map_identity`, `clippy::needless_borrow`, `clippy::let_and_return`, `unused_mut`, `dead_code` constants.
- Connector: `clippy::type_complexity` at `connector/src/binancefutures/rest.rs::BinanceFuturesClient::submit_orders` (use a type alias or `struct` for the tuple).

Log:
- Full output saved at `.ph_target/agent_02/clippy.log` (cargo exit code 101 due to the example build errors).
~~~~

## agent_03_unsafe_audit_core_backtest (status: needs_attention)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_03_unsafe_audit_core_backtest/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_7cc20238/final.json`

~~~~text
Unsafe audit (core backtest) findings for `hftbacktest`.

1) Unsafe blocks / unsafe items and assumed invariants

A. `hftbacktest/src/backtest/data/mod.rs`
- `pub unsafe trait POD` (line 23): implementor guarantees C-like “plain old data” suitability for raw byte storage + reinterpretation (no invalid bit-patterns, no pointers/references requiring provenance invariants, no Drop, no padding read as initialized, stable layout, etc.).
- `Data::from_data` uses `slice::from_raw_parts(data.as_ptr() as *const u8, byte_len)` (line 64) then copies bytes into a new buffer (lines 68–73): assumes it is legal to view all bytes of `[D]` as initialized `u8` (i.e., no uninitialized padding / “bytes are initialized”).
- `pub unsafe fn Data::from_data_ptr(ptr, offset)` (line 81): caller guarantees `offset <= ptr.len()`, `offset` is aligned for `D`, and the remaining bytes are a whole-number of `D` elements whose bytes form valid `D` values.
- `pub unsafe fn Data::get_unchecked` (line 95): caller guarantees `index < self.len()`.
- `Index`/`IndexMut` for `Data` (lines 107–135) do a bounds check, then `&*(self.ptr.at(i) as *const D)` / `&mut *(...)` (lines 120, 134): assumes alignment + validity of `D` at that byte offset.
- `pub unsafe fn DataPtr::from_ptr(*mut [u8])` (line 160): caller guarantees pointer remains valid for `DataPtr`’s lifetime.
- `pub unsafe fn DataPtr::at(index)` (line 179): caller guarantees `index < len` and pointer provenance supports `add`.
- `Index`/`IndexMut` for `DataPtr` deref `&*self.ptr` / `&mut *self.ptr` (lines 202, 213): assumes `self.ptr` is non-null and points to a valid (and, for `u8`, initialized) slice.
- `Drop for DataPtr` calls `AlignedArray::from_raw(self.ptr)` (line 221): assumes `self.ptr` originated from `AlignedArray::into_raw` exactly once (no double-free), with matching alignment/layout.

B. `hftbacktest/src/backtest/data/npy/mod.rs`
- `unsafe { Data::from_data_ptr(buf, 10 + header_len) }` (line 292): assumes `10+header_len` is within buffer, aligned for `D`, and the bytes after the header are valid `D` values.
- `vec_as_bytes` uses `slice::from_raw_parts(ptr, len)` (line 380): assumes it is legal to view all bytes of `[T]` as initialized `u8` (no uninitialized padding).

C. `hftbacktest/src/backtest/data/reader.rs`
- `unsafe impl Send for DataSend<D>` (line 180): assumes the contained `Data<D>` is transferred with effectively-unique ownership (no other `Rc` clones exist or can be accessed concurrently), so non-atomic refcounting is never touched from multiple threads.

D. `hftbacktest/src/backtest/evs.rs`
- `unsafe { *self.timestamp.get_unchecked(0) }` (line 45): assumes timestamp array length > 0.
- `unsafe { mem::transmute::<usize, EventIntentKind>(evst_no & 3) }` (line 57): assumes `(evst_no & 3)` is always a valid discriminant (0..=3).
- `unsafe { self.timestamp.get_unchecked_mut(evst_no) }` in `update`/`invalidate` (lines 67, 93): assumes `evst_no < self.timestamp.len()`.

E. `hftbacktest/src/backtest/mod.rs`
- `unsafe { self.local.get_unchecked_mut(ev.asset_no) }` and same for `exch` (lines 777, 800, 822, 845): assumes `ev.asset_no < self.local.len()` / `< self.exch.len()`.

F. `hftbacktest/src/backtest/order.rs`
- Multiple `unsafe { &*self.order_list.get() }` / `unsafe { &mut *... }` (lines 20, 36, 46, 51, 56, 61, 66): assumes no overlapping mutable+shared borrows to the same `VecDeque` can be created through safe API usage (single-threaded, mutation only behind `&mut self`, and no method returns references into the deque).

G. `hftbacktest/src/backtest/recorder.rs`
- `unsafe impl POD for Record` (line 29): claims `Record` is safe for raw byte interpretation.
- `unsafe { self.values.get_unchecked_mut(asset_no) }` (line 50): assumes `asset_no < self.values.len()`.

H. `hftbacktest/src/backtest/models/latency.rs`
- `unsafe impl POD for OrderLatencyRow` (line 71): claims it is safe for raw byte interpretation.

I. `hftbacktest/src/utils/aligned.rs` (critical underpinning for backtest)
- `Drop` uses `Layout::from_size_align_unchecked` + `alloc::dealloc` (lines 22–26): assumes layout is valid and matches allocation.
- `new` uses `Layout::from_size_align_unchecked`, `alloc::alloc`, `NonNull::new_unchecked(slice_from_raw_parts_mut(...))` (lines 46–54): assumes allocation succeeds, pointer is non-null, and the raw slice pointer is valid.
- `as_mut_slice` / `as_slice` return `&mut [T]` / `&[T]` via `ptr.as_mut()` / `ptr.as_ref()` (lines 66, 76): assumes the memory holds *initialized* `T` values.
- `unsafe fn from_raw(ptr)` (line 100): assumes pointer came from `into_raw` exactly once.

2) UB / invalid-invariant risks found

Definite UB (can occur in normal backtest usage):
- Uninitialized-reference UB in `AlignedArray::new`:
  - `AlignedArray::new` allocates but does not initialize elements, yet safe methods (`as_mut_slice`, `Deref`, indexing) create `&mut [T]` / `&[T]` to that memory.
  - Creating references to uninitialized `T` is UB (even if you immediately overwrite).
  - This impacts core backtest immediately:
    - `EventSet::new` allocates `AlignedArray<i64, CACHE_LINE_SIZE>` then writes via indexing (evs.rs:35–38).
    - `DataPtr::new` allocates `AlignedArray<u8, CACHE_LINE_SIZE>` then is indexed/mutably sliced by `read_npy` (npy/mod.rs:239–244).

Safe API that can trigger UB (soundness bugs):
- `EventSet::{update_*, invalidate_*}` are safe/public but use `get_unchecked_mut` internally (evs.rs:67, 93). Passing `asset_no >= num_assets` causes OOB write UB from safe code.
- `DataPtr` safe `Index`/`IndexMut` deref `&*self.ptr` / `&mut *self.ptr` (data/mod.rs:202, 213). `DataPtr::default()` sets `ptr` to a null slice pointer; any indexing of a default/empty `DataPtr` is immediate UB (null deref) from safe code.
- `Data<D>` is `Clone` (shared `Rc`) but also implements `IndexMut` returning `&mut D` into shared backing storage (data/mod.rs:124–135). Two clones can create two mutable references to the same element (aliasing UB) from safe code.

High-risk “conditional UB” (depends on inputs / downstream unsafe impls):
- Byte-view of typed slices (`from_raw_parts` to `u8`) in `Data::from_data` (data/mod.rs:64) and `vec_as_bytes` (npy/mod.rs:380): if `D/T` has any padding bytes that are not guaranteed initialized, reading them as `u8` is UB.
- Reinterpreting file bytes as `D` via `Data::from_data_ptr` (npy/mod.rs:292) and `Data` indexing casts (data/mod.rs:120/134): UB if bytes are not a valid `D` (e.g., `bool` fields with non-{0,1}, enums with invalid discriminants, references/pointers, niche types), or if alignment exceeds `CACHE_LINE_SIZE`.
  - `read_npy` checks `10+header_len` is a multiple of `CACHE_LINE_SIZE` (64) but does not enforce `align_of::<D>() <= 64` or `offset % align_of::<D>() == 0` explicitly.
  - It also does not validate that the on-disk payload length matches `shape[0] * size_of::<D>()` before exposing `Data<D>`.
- `unsafe impl Send for DataSend<D>` (reader.rs:180): likely OK with current private usage (send freshly-created `Data` across threads), but still a fragile invariant (any additional clones in the loader thread would make this a data-race on `Rc` refcount).

3) Specific hardening steps (targeted)

Core soundness fixes (highest priority):
- Redesign `AlignedArray` so it never creates `&[T]` / `&mut [T]` to uninitialized elements.
  - Options:
    - Make it store `MaybeUninit<T>` internally and only expose initialized slices after explicit initialization (e.g., `new_uninit`, `assume_init`, safe fill APIs).
    - Or constrain `new` to `T: Zeroable` and allocate with `alloc_zeroed`, plus add a separate `new_uninit` for general `T`.
    - For current usage (`u8` and `i64`), a pragmatic fix is to allocate zeroed and then initialize via raw-pointer writes (no intermediate references) before exposing slice APIs.
- Make `EventSet` bounds-safe:
  - Either make `update_*`/`invalidate_*` return `Result`/panic on OOB using checked indexing, or store `num_assets` and validate `asset_no < num_assets` (and use `checked_mul(4)`/`checked_add`).
  - Alternatively, make these methods `unsafe` if you insist on unchecked indexing.
- Make `DataPtr` safe indexing sound:
  - Represent the pointer as `NonNull<u8>` + `len` (use `NonNull::dangling()` for len=0) and ensure empty never derefs null.
  - Avoid constructing `&[u8]` / `&mut [u8]` from uninitialized storage; ensure buffers are initialized before creating references.
- Fix `Data<D>` mutability aliasing:
  - Remove `IndexMut` (make `Data` read-only), or implement copy-on-write via `Rc::get_mut`/deep-clone backing storage before returning `&mut D`.

POD / file-validation hardening:
- Replace/strengthen `POD` with a well-defined byte-cast trait (`bytemuck::Pod` / `zerocopy::FromBytes + AsBytes`) and enforce it for `Data`/Npy serialization.
- In `read_npy`:
  - Validate `shape[0] * size_of::<D>()` matches remaining bytes.
  - Validate alignment requirements: `offset % align_of::<D>() == 0` and (if you rely on cache-line alignment) `align_of::<D>() <= CACHE_LINE_SIZE`.
- Replace `mem::transmute` for `EventIntentKind` with a total `match` / `TryFrom<u8>` (even if current mask is correct).

Testing / verification suggestions:
- Add Miri-focused unit tests:
  - `AlignedArray` smoke test: allocate + initialize path without UB.
  - `EventSet` bounds test: calling `update_*` with `asset_no == num_assets` should panic/Err (not UB).
  - `Data` aliasing test: two clones attempting mutable indexing should be prevented (panic/clone-on-write).
- Add file-structure tests for `read_npy`: mismatched payload length and misalignment should be rejected.

Build note (not UB, but impacts CI): `cargo test -p hftbacktest --no-run` currently fails due to several non-compiling examples; `cargo test -p hftbacktest --lib --no-run` succeeds.
~~~~

## agent_04_live_bot_ipc_safety (status: needs_attention)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_04_live_bot_ipc_safety/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_60d42477/final.json`

~~~~text
Audited `live/` bot + iceoryx IPC for safety/correctness issues that could crash or mis-handle live trading.

Potential OOB / unsafe assumptions
- `hftbacktest/src/live/bot.rs:213` / `:242` / `:274`: `unsafe { self.instruments.get_unchecked_mut(inst_no) }` assumes `Channel::recv_timeout` always returns a valid `inst_no` (0..len). Any bug/mismatch in a `Channel` impl can turn into UB (memory corruption), not just a clean error.
- `hftbacktest/src/live/ipc/iceoryx.rs:337`: `unsafe { self.unique_channel.get_unchecked(self.ch_i) }` is currently “locally safe” (bounded by construction), but still relies on invariants staying true forever (no future edits that mutate `unique_channel`/`ch_i`).

IPC memory safety / message bounds
- `hftbacktest/src/live/ipc/iceoryx.rs:170-179`: `loan_slice_uninit(MAX_PAYLOAD_SIZE)` + `unsafe { sample.assume_init() }` treats an uninitialized payload as `[u8]`. If the iceoryx send path copies/sends the entire slice (not just `len`), that can read uninitialized bytes (Rust UB) and can leak previous memory contents cross-process.
  - Safer pattern: avoid `assume_init` on the whole buffer (use initialized loan APIs), or explicitly initialize the full payload (e.g., zero-fill) before `assume_init`, or redesign to only send an initialized length.
- `hftbacktest/src/live/ipc/iceoryx.rs:198-203`: receiver trusts `CustomHeader.len` and does `&payload[0..len]` with no bounds check. If `len > payload.len()` (corruption/bug/malicious peer), this panics and takes down the bot process.
  - Safer handling: validate `len <= sample.payload().len()` and return a structured error (drop message + log) instead of panicking.
- `hftbacktest/src/live/ipc/iceoryx.rs:41-55`: many decode/encode errors are handled cleanly, but the two issues above can still crash/UB before those errors surface.
- `hftbacktest/src/live/ipc/iceoryx.rs:35-39`: `CustomHeader { len: usize }` bakes in pointer-width ABI; mixed 32/64-bit processes (or other language peers) will disagree on header layout/size. Using a fixed-width type like `u32`/`u64` for `len` would be more robust.

Panic/unwrap paths and safer alternatives
- Time unwraps: `Utc::now().timestamp_nanos_opt().unwrap()` at `hftbacktest/src/live/bot.rs:246`, `:390`, `:422`, `:578` can panic if chrono can’t represent the timestamp (rare today, but a hard crash is still undesirable for live trading). Prefer a non-panicking time source or explicit fallback.
- Asset indexing unwraps: `hftbacktest/src/live/bot.rs:439`, `:444`, `:451`, `:461`, `:469`, `:479`, `:650`, `:654` will panic on invalid `asset_no`. If `asset_no` can ever be user-driven or derived from external input, these should return `BotError::InstrumentNotFound` (or similar) instead.
- `hftbacktest/src/live/ipc/iceoryx.rs:319`: `.unwrap()` on `channel.get(&i.connector_name)` is “logically safe” given the preceding construction, but still a hard panic if invariants are broken (e.g., future edits). Converting to an error improves resilience.
- `hftbacktest/src/live/ipc/iceoryx.rs:266` (indirect): `IceoryxUnifiedChannel::new` asserts non-empty; building with 0 instruments will panic rather than return a `BuildError`.

Correctness bugs that can break live trading
- Batch-mode return value bug: in `hftbacktest/src/live/bot.rs:306-312`, when a waited-for response/feed is received during `batch_mode`, the code returns `ElapseResult::Ok` at `BatchEnd` instead of returning `MarketFeed`/`OrderResponse`.
  - This can cause `wait_next_feed(...)` / `wait_order_response(...)` to return `Ok` even though the awaited event happened, leading to “missed wakeups”, strategy loops that spin/wait unnecessarily, or timeouts firing incorrectly.
- Negative duration cast: `hftbacktest/src/live/bot.rs:296` does `Duration::from_nanos(duration as u64)`. If any caller passes a negative `duration`/`timeout`, it becomes a huge `u64` duration (effectively hanging waits far longer than intended).
- `modify()` is unimplemented: `hftbacktest/src/live/bot.rs:546-556` is `todo!()` and will panic if a strategy calls modify in live mode.
- Trade buffer grows unbounded: `Instrument.last_trades` is a `Vec` (`hftbacktest/src/live/mod.rs:22`) and `process_event` always `push`es trades when capacity > 0 (`hftbacktest/src/live/bot.rs:223-226`). That does not enforce a cap; it just enables/disables collection.
  - Unless user code frequently calls `clear_last_trades`, this can grow without bound and degrade latency / OOM the process.
- Silent event drops on symbol mismatch: `hftbacktest/src/live/ipc/iceoryx.rs:354-360` drops Feed/Order/Position events if `symbol_to_inst_no` has no entry for the event symbol, with no error/log. This can manifest as “stuck waits” (no order response) or stale positions/market data if connector symbology differs even slightly.
- Latency semantics ambiguity: `hftbacktest/src/live/bot.rs:243-247` stores `(order.local_timestamp, order.exch_timestamp, now)` but it’s unclear that `order.local_timestamp` is stable and always represents the intended “send time” vs “connector receive time”; if not, reported latency can be misleading.

iceoryx wait/loop behavior
- `hftbacktest/src/live/ipc/iceoryx.rs:334-367`: `node.wait(Duration::from_nanos(1))` is just a nanosleep (not event-driven in iceoryx2 0.6.1), so this is effectively a tight polling loop with very small sleeps. This can burn CPU and add jitter under load. A proper event/notification-driven receive (or adaptive backoff) would reduce overhead.

Suggested hardening (no code changes made)
- Replace `get_unchecked_mut` with checked indexing (or guard with `debug_assert!(inst_no < instruments.len())` + return `BotError::InstrumentNotFound` on failure) to avoid UB.
- Fix batch-mode signaling by remembering the last non-`Ok` result seen in the batch and returning that at `BatchEnd`.
- In iceoryx sender: avoid `assume_init` on uninitialized buffers unless you fully initialize; in receiver: validate `len` before slicing.
- Log and/or surface an error when receiving an event for an unknown symbol instead of silently dropping it.
- Make `modify()` return a real error instead of panicking, or clearly gate it from live usage.
- Guard against negative `duration`/`timeout` inputs.

(Also inspected iceoryx2 upstream `Node::wait` semantics in the local cargo registry to confirm it is nanosleep-based, not readiness-based.)
~~~~

## agent_05_py_ffi_boundary (status: needs_attention)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_05_py_ffi_boundary/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_101501b2/final.json`

~~~~text
Audited `py-hftbacktest`'s C-ABI surface (raw pointers + enum conversions) for UB hazards. High-confidence UB risks found:

1) **Invalid enum discriminants via `mem::transmute::<u8, Enum>`**
- `py-hftbacktest/src/live.rs:145`, `py-hftbacktest/src/live.rs:152`, `py-hftbacktest/src/live.rs:174`, `py-hftbacktest/src/live.rs:175`, `py-hftbacktest/src/live.rs:388`, `py-hftbacktest/src/live.rs:395`, `py-hftbacktest/src/live.rs:417`, `py-hftbacktest/src/live.rs:418`
- `py-hftbacktest/src/backtest.rs:142`, `py-hftbacktest/src/backtest.rs:149`, `py-hftbacktest/src/backtest.rs:171`, `py-hftbacktest/src/backtest.rs:172`, `py-hftbacktest/src/backtest.rs:404`, `py-hftbacktest/src/backtest.rs:411`, `py-hftbacktest/src/backtest.rs:433`, `py-hftbacktest/src/backtest.rs:434`
`TimeInForce` and `OrdType` are `#[repr(u8)]` enums with a defined set of valid values (incl. `Unsupported=255`) in `hftbacktest/src/types.rs:409` and `hftbacktest/src/types.rs:438`. Transmuting arbitrary `u8` to these enums is UB when the value is not one of the declared discriminants.

2) **Leaked `Vec` freed with the wrong capacity (`Vec::from_raw_parts(ptr, len, len)`)**
- `py-hftbacktest/src/depth.rs:80-93` leaks a `Vec<Event>` via `forget(snapshot)` and returns `ptr` + `len`.
- `py-hftbacktest/src/depth.rs:96-98` reconstructs the `Vec` using `capacity=len`.
This is UB whenever the real capacity differs from `len`. Even though `shrink_to_fit()` is called, Rust does not guarantee capacity==len.

3) **Raw pointer deref + out-pointer writes without null validation**
Examples (not exhaustive):
- `py-hftbacktest/src/live.rs:36`, `py-hftbacktest/src/live.rs:45`, `py-hftbacktest/src/live.rs:56`, `py-hftbacktest/src/live.rs:58-62`, `py-hftbacktest/src/live.rs:93`, `py-hftbacktest/src/live.rs:120`, `py-hftbacktest/src/live.rs:129`, `py-hftbacktest/src/live.rs:246-249`, `py-hftbacktest/src/live.rs:268-271`
- `py-hftbacktest/src/backtest.rs:36`, `py-hftbacktest/src/backtest.rs:45`, `py-hftbacktest/src/backtest.rs:56`, `py-hftbacktest/src/backtest.rs:58-62`, `py-hftbacktest/src/backtest.rs:90`, `py-hftbacktest/src/backtest.rs:253-260`, `py-hftbacktest/src/backtest.rs:277-281`
- `py-hftbacktest/src/depth.rs:15`, `py-hftbacktest/src/depth.rs:85`, `py-hftbacktest/src/depth.rs:88-91`, `py-hftbacktest/src/depth.rs:172-174`, `py-hftbacktest/src/depth.rs:181-184`
- `py-hftbacktest/src/order.rs:13`, `py-hftbacktest/src/order.rs:22`, `py-hftbacktest/src/order.rs:28`, `py-hftbacktest/src/order.rs:42`
- `py-hftbacktest/src/fuse.rs:46-47`, `py-hftbacktest/src/fuse.rs:93-95`
Passing a null pointer (or an already-freed/invalid pointer) from Python/C is immediate UB.

4) **Returning pointers into Rust-owned / mutable internal buffers (lifetime hazards / UAF)**
Borrowed pointers are returned with no enforceable lifetime contract:
- Depth pointer borrowed from bot/backtest: `py-hftbacktest/src/live.rs:41-48`, `py-hftbacktest/src/live.rs:283-291`, `py-hftbacktest/src/backtest.rs:41-48`, `py-hftbacktest/src/backtest.rs:300-307`.
- Last-trades slice pointer borrowed from bot/backtest: `py-hftbacktest/src/live.rs:51-62`, `py-hftbacktest/src/live.rs:294-305`, `py-hftbacktest/src/backtest.rs:51-62`, `py-hftbacktest/src/backtest.rs:309-321`.
- Orders map pointer borrowed from bot/backtest: `py-hftbacktest/src/live.rs:217-224`, `py-hftbacktest/src/live.rs:460-467`, `py-hftbacktest/src/backtest.rs:227-234`, `py-hftbacktest/src/backtest.rs:489-496`.
- StateValues pointer borrowed from bot/backtest: `py-hftbacktest/src/live.rs:226-233`, `py-hftbacktest/src/live.rs:469-476`, `py-hftbacktest/src/backtest.rs:236-243`, `py-hftbacktest/src/backtest.rs:498-505`.
- ROIVector bid/ask depth slice pointers borrowed from depth: `py-hftbacktest/src/depth.rs:166-174`, `py-hftbacktest/src/depth.rs:176-184`.
- Fused events slice borrowed from `FuseMarketDepth`: `py-hftbacktest/src/fuse.rs:88-96`.
Any later mutation (e.g. advancing backtest, clearing buffers, pushing new fused events) can reallocate and invalidate previously returned pointers; dropping the owning bot/backtest makes all such pointers dangling.

5) **Destructor-like `close()` consumes `Box::from_raw` (double-free / UAF risk)**
- `py-hftbacktest/src/live.rs:74-86`, `py-hftbacktest/src/live.rs:317-329`
- `py-hftbacktest/src/backtest.rs:74-86`, `py-hftbacktest/src/backtest.rs:333-345`
These functions *take ownership* and free the allocation behind `hbt_ptr`. Calling `close()` twice, or calling any other method after `close()`, is UAF/likely crash. The current Python wrapper appears to call `close()` without nulling the stored pointer (e.g. `py-hftbacktest/hftbacktest/binding.py:938-947`).

6) **`orders_values()` iterator handle has unenforced lifetime + awkward freeing semantics**
- `py-hftbacktest/src/order.rs:33-38` boxes a `hash_map::Values<'a, ..>` iterator that borrows the `HashMap`.
- `py-hftbacktest/src/order.rs:41-49` drops the box when iteration ends (`None`), but provides no explicit free for early exit; calling `orders_values_next()` again after it returned null is UB (use-after-free), and dropping the Python-side wrapper early leaks.

Safer conversions / patterns to consider (no code changes made):
- Replace `mem::transmute::<u8, TimeInForce/OrdType>` with explicit `match` on known discriminants.
  - Either map unknown values to `Unsupported`, or (safer) return a dedicated FFI error code like `ERR_INVALID_ENUM` and do not call into `hbt.submit_*`.
  - Example shape: `fn ord_type_from_u8(v: u8) -> Result<OrdType, i64> { match v { 0=>Ok(Limit), 1=>Ok(Market), 255=>Ok(Unsupported), _=>Err(ERR_INVALID_ENUM) } }`.
- Make all pointer-deref externs `pub unsafe extern "C" fn ...` and add `is_null()` checks for `self` pointers and out-pointers (`len_ptr`, `exch_ts`, etc.), returning a safe sentinel (`0`, `false`, null) rather than UB on null.
- Separate *resource shutdown* from *deallocation*:
  - Change `*_close()` to operate on `&mut *ptr` (does not free), and add `*_free()` to `drop(Box::from_raw(ptr))` (with null check). Alternatively, keep consuming close but ensure the Python wrapper sets the stored pointer to null after calling.
- Fix `hashmapdepth_snapshot`/`hashmapdepth_snapshot_free` to avoid capacity mismatch:
  - Return capacity as an additional out-param and free with `Vec::from_raw_parts(ptr, len, cap)`, or
  - Prefer `Box<[Event]>`: `let boxed = snapshot.into_boxed_slice(); let ptr = Box::into_raw(boxed) as *mut Event;` and free via `Box::from_raw(slice_from_raw_parts_mut(ptr, len))`.
- For borrowed buffer returns (last_trades, fused_events, bid/ask depth), either:
  - Document a strict validity window (“pointer valid until next mutation / next call / until bot is freed”), and/or
  - Provide copy-out APIs that allocate an owned buffer with an explicit free function.
- For `orders_values`, consider an opaque iterator handle that either (a) copies order IDs/values into an owned `Vec` at creation, or (b) provides an explicit `*_free` and uses `*mut *mut Handle` so Rust can set the handle to null when it self-frees.

Minimal tests that would catch these classes of issues (suggestions only):
- Rust (best at catching UB): run under Miri.
  - Add a small unit test that calls `hashmapdepth_snapshot` and then `hashmapdepth_snapshot_free` (looped), and run `cargo +nightly miri test -p py-hftbacktest`. If capacity/layout mismatches occur, Miri typically reports invalid deallocation.
  - Add a test that passes an invalid `u8` for `time_in_force`/`order_type` through the FFI submit function (after adding safe conversion). Before the fix, Miri should flag invalid enum discriminant when `transmute` is used.
- Python regression tests (will often crash the interpreter if unfixed, so run in a subprocess):
  - `test_invalid_enum_does_not_segfault`: call `submit_buy_order(..., time_in_force=42, ...)` and assert it returns a defined error code.
  - `test_close_is_idempotent_or_invalidates_ptr`: call `close()` twice and assert no segfault (or assert the object refuses subsequent calls because pointer was nulled).
  - `test_snapshot_free_stress`: in a loop, `arr = depth.snapshot(); depth.snapshot_free(arr)` and ensure no crash/leak under ASAN builds.

Net: the most urgent fixes are (a) removing `mem::transmute` on untrusted `u8`, (b) fixing snapshot free capacity handling, and (c) clarifying/repairing close/free ownership so Python cannot accidentally use freed pointers.
~~~~

## agent_06_npy_and_data_parsing (status: needs_attention)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_06_npy_and_data_parsing/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_f996f750/final.json`

~~~~text
Findings (bounds/overflow/panic):
- `hftbacktest/src/backtest/data/npy/mod.rs`: `read_npy` slices `buf[0..6]`, `buf[6..8]`, `buf[8..10]`, and `buf[10..10+header_len]` without first checking `size >= 10` and `10 + header_len <= size` (panics on short/truncated/malformed inputs).
- `hftbacktest/src/backtest/data/npy/mod.rs`: `NpyHeader::from_header(&header).unwrap()` will panic on any malformed header instead of returning `InvalidData`.
- `hftbacktest/src/backtest/data/npy/mod.rs`: the read loop `while read_size < size { read_size += reader.read(...) }` can spin forever if `read()` returns `0` before `size` bytes are read (e.g., truncated file, short Zip entry, I/O anomaly).
- `hftbacktest/src/backtest/data/mod.rs`: `Data::len()` computes `(self.ptr.len() - self.offset) / size_of::<D>()`; if `offset > ptr.len()` this underflows (wraps) and can yield a huge length. The current `.npy` slicing panics earlier for most malformed cases, but the API is still footgun-prone.
- `hftbacktest/src/backtest/data/mod.rs`: `Data::{index,index_mut,get_unchecked}` use `offset + index * size` with unchecked arithmetic; if callers ever pass adversarially large indices, arithmetic can wrap and defeat the bounds check (`i + size > len`) causing wrong-element access and unsafe pointer casts.

Findings (header parsing OOB safety):
- `hftbacktest/src/backtest/data/npy/parser.rs` is &str-based (no OOB reads itself), but `read_npy`’s construction of the header string can panic before the parser runs.

Findings (correctness / silent corruption risks):
- `hftbacktest/src/backtest/data/npy/mod.rs`: `check_field_consistency()` ignores field-count mismatches (uses `zip` and never checks lengths). This can silently accept missing/extra trailing fields (including potential end-padding fields) as “only name mismatch” and proceed to reinterpret bytes as `D`.
- `hftbacktest/src/backtest/data/npy/mod.rs`: if the header omits `descr`, `NpyHeader::from_header` returns `descr = []`; current logic treats this as “name mismatch” (via `check_field_consistency` returning `Ok([])`) and proceeds, potentially reinterpreting arbitrary bytes as `D`.
- `hftbacktest/src/backtest/data/npy/mod.rs`: `shape` is only checked for rank (`len() == 1`); the element count in the header is not validated against the remaining byte length. This can silently (a) read more records than `shape[0]` suggests, (b) truncate if trailing bytes don’t form a full `D`, or (c) mis-handle files with end padding.
- `hftbacktest/src/backtest/data/npy/mod.rs`: strict `CACHE_LINE_SIZE` (64) alignment requirement for `10 + header_len` will reject many valid `.npy` files (NumPy typically pads to 16-byte boundaries). Not silent, but a compatibility/correctness constraint that can surprise users.
- `hftbacktest/src/backtest/data/npy/mod.rs`: writer uses `u16` for header length (`header_str.len() as u16`); very large headers truncate, producing an invalid file and potential mis-parse.

Endianness handling:
- No byte-swapping is performed. The code relies on exact `descr` string equality to reject mismatched endianness. This avoids silent corruption for explicit `<`/`>` mismatches, but there’s no normalization (e.g., treating `=` as native) and no explicit “big-endian unsupported” check beyond string mismatch.

Recommended fixes (no code changes made):
- In `read_npy`, add upfront bounds checks (`size >= 10`, `header_len` bounded, `10+header_len <= size`) and replace all `unwrap()` with `?` returning `InvalidData`.
- Fix the read loop to detect EOF (`read()==0`) and return `UnexpectedEof`.
- Require `header.descr.len() == D::descr().len()` and error on mismatch; also require presence of mandatory keys.
- Validate `header.shape[0] * size_of::<D>() == size - (10+header_len)` (or at least that it matches and remainder is 0) to prevent silent truncation/overread semantics.
- In `Data` index math, use checked arithmetic (or at minimum `usize::checked_mul/checked_add`) to make the bounds check robust.

No source files were modified.
~~~~

## agent_07_depth_marketdepth_logic (status: needs_attention)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_07_depth_marketdepth_logic/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_3debfaa7/final.json`

~~~~text
Findings (index/range safety + invariants)

1) Definite out-of-range / UB via `get_unchecked` in `ROIVectorMarketDepth`
- `depth_below()` clamps `start` only with `min(roi_ub)` and can go below `roi_lb`, then casts negative to `usize` and dereferences with `get_unchecked` -> UB. (`hftbacktest/src/depth/roivectormarketdepth.rs:31`)
  - Trigger scenario: ROI does not include current best ask tick, but L3 methods still update `best_ask_tick` globally.
    Example: ROI=[1000,2000] ticks; add buy at 5000 (best_bid_tick=5000), then add sell at 500 (best_ask_tick=500). `add_sell_order` sees `best_bid_tick >= best_ask_tick` and calls `depth_below(&bid_depth, start=best_ask_tick, end=low_bid_tick, ...)` where `start < roi_lb` => negative index => UB. (`hftbacktest/src/depth/roivectormarketdepth.rs:542`, `hftbacktest/src/depth/roivectormarketdepth.rs:561`)
- `clear_depth()` uses `best_bid_tick`/`best_ask_tick` to compute vector indices without clamping to ROI or vector length; if those ticks are outside ROI, loops can pass indices >= `len` (or negative for sell) into `get_unchecked_mut` -> UB. (`hftbacktest/src/depth/roivectormarketdepth.rs:273`, `hftbacktest/src/depth/roivectormarketdepth.rs:314`)
  - Buy side: `to = self.best_bid_tick + 1 - self.roi_lb` can exceed `ask_depth.len()` if `best_bid_tick > roi_ub` (possible via L3 ops). (`hftbacktest/src/depth/roivectormarketdepth.rs:280`)
  - Sell side: `from = self.best_ask_tick - self.roi_lb` can be negative if `best_ask_tick < roi_lb` (possible via L3 ops) and will be cast to `usize` in `get_unchecked_mut`. (`hftbacktest/src/depth/roivectormarketdepth.rs:318`)

2) Likely logic bug in `ROIVectorMarketDepth::clear_depth` (Sell)
- `to` is computed as `(clear_upto + 1 - self.roi_ub).min(self.ask_depth.len() as i64)`; this appears dimensionally wrong (mixes tick-space with index-space incorrectly) and will often produce empty/incorrect ranges even when `best_ask_tick` is inside ROI. Likely intended: `(clear_upto + 1 - self.roi_lb)` then clamp to `[0,len]`. (`hftbacktest/src/depth/roivectormarketdepth.rs:319`)

3) ROI-vector L2 update stores “deleted” nonzero qty (lot-rounding inconsistency)
- `update_bid_depth` / `update_ask_depth` writes `*v = qty` unconditionally, even when `qty_lot == 0` (i.e., should be treated as deletion). That can leave small positive depth (e.g. 0.4 lot) in the vector while the logic treats it as removed, and later scans (`> 0.0`) can “resurrect” levels / best ticks. (`hftbacktest/src/depth/roivectormarketdepth.rs:162`, `hftbacktest/src/depth/roivectormarketdepth.rs:235`)

4) Snapshot/apply invariants
- No implementation enforces bid<ask or non-negative qty on snapshot/apply; a crossed snapshot will remain crossed until later updates (and for `BTreeMarketDepth` there is no crossing recovery logic at all). (`hftbacktest/src/depth/btreemarketdepth.rs:224`, `hftbacktest/src/depth/hashmapmarketdepth.rs:313`, `hftbacktest/src/depth/roivectormarketdepth.rs:464`)
- `FusedHashMapMarketDepth::apply_snapshot` does not reset `best_bid_timestamp` / `best_ask_timestamp`, yet uses them to gate updates (`ts >= self.best_*_timestamp`). Applying an older snapshot after processing newer data can leave `best_*_tick` invalid even though `*_depth` is populated. (`hftbacktest/src/depth/fuse.rs:564`)

5) Consistency hazards mixing L2 + L3 paths
- In `HashMapMarketDepth`/`BTreeMarketDepth`, L3 `delete_order` assumes the aggregated depth entry exists (`get_mut(...).unwrap()`). If L2 `clear_depth`/updates remove that level while the L3 `orders` map still contains orders there, delete/modify can panic (not OOB, but breaks invariants). (`hftbacktest/src/depth/hashmapmarketdepth.rs:456`, `hftbacktest/src/depth/btreemarketdepth.rs:307`)

Minimal tests to lock invariants (no code changes made here)
- `ROIVectorMarketDepth` outside-ROI safety/regression:
  - Create ROI where live orders are outside (e.g. roi=[100.0,200.0], tick_size=0.1). Add buy at 500.0 and sell at 50.0; then call `add_sell_order`/`modify_order` paths that trigger crossing logic. Test should assert it does not crash under `cargo miri test` (this case is UB-prone today).
  - Decide intended semantics and assert them:
    - If ROI-vector is ROI-only: assert `best_bid_tick`/`best_ask_tick` remain INVALID or within `[roi_lb,roi_ub]` after adding outside-ROI L3 orders.
    - If it’s global-best: assert any vector indexing helpers clamp `start/end` to `[roi_lb,roi_ub]` before unsafe indexing.
- `ROIVectorMarketDepth::clear_depth(Sell)` correctness:
  - Populate asks at two ticks inside ROI, call `clear_depth(Sell, px_between)`, assert cleared indices are exactly the expected range and `best_ask_tick` updates to the next remaining level.
- `ROIVectorMarketDepth` lot-rounding deletion:
  - With `lot_size=0.001`, call `update_bid_depth(price, 0.0004, ts)` and assert stored level becomes 0 and does not affect best tick.
- `FusedHashMapMarketDepth::apply_snapshot` timestamp reset:
  - Advance `best_*_timestamp` via updates, then apply a snapshot with older `exch_ts`; assert best ticks recompute from snapshot (or explicitly define expected behavior).
~~~~

## agent_08_connector_resilience (status: needs_attention)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_08_connector_resilience/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_7033ae88/final.json`

~~~~text
Reviewed `connector/src/**` (Binance spot/futures, Bybit) for panic/unwrap hazards and protocol-handling/resilience bugs.

High-risk panic/unwrap on real-world data (should be handled, not `unwrap()`):
- Bybit private WS op responses: `resp.success.unwrap()` and `resp.ret_msg.unwrap()` can panic when fields are absent/`null` (e.g., partial op responses). See `connector/src/bybit/private_stream.rs:79` and `connector/src/bybit/private_stream.rs:96` / `connector/src/bybit/private_stream.rs:101`.
- Bybit public stream timestamps: `stream.cts.unwrap()` can panic when `cts` is missing; should fall back to `stream.ts` or `Utc::now()` and/or treat missing `cts` as parse error. See `connector/src/bybit/public_stream.rs:67` / `connector/src/bybit/public_stream.rs:85` / `connector/src/bybit/public_stream.rs:106` / `connector/src/bybit/public_stream.rs:124`.
- Bybit REST position list: `resp.result.list.unwrap()` can panic if the response omits `list`. Return a structured `BybitError` instead. See `connector/src/bybit/rest.rs:113`.
- Exchange data -> panic: unknown Bybit position side triggers `panic!` when `size != 0.0`; safer to log + drop/mark unsupported. See `connector/src/bybit/private_stream.rs:165` and `connector/src/bybit/private_stream.rs:377`.
- Many `send(...).unwrap()` on mpsc/broadcast channels can panic during shutdown/reconnect races (receiver dropped). Particularly concerning inside spawned tasks (e.g., REST snapshot fetch) where a disconnect can drop the receiver. Example: `connector/src/binancespot/market_data_stream.rs:80`.
- Order-manager removals use `HashMap::remove(...).unwrap()` under assumptions that can be violated by out-of-order WS/REST events (ghost orders / late updates). Examples: `connector/src/binancefutures/ordermanager.rs:104`, `connector/src/binancespot/ordermanager.rs:89`, `connector/src/bybit/ordermanager.rs:58`, `connector/src/bybit/ordermanager.rs:222`.

Protocol/decoding correctness bugs:
- Bybit execution price tick calculation is wrong: divides by `order.price_tick` instead of `order.tick_size`. This will produce nonsense `exec_price_tick` (often ~0) and break fill price tracking. See `connector/src/bybit/ordermanager.rs:72` and `connector/src/bybit/ordermanager.rs:88`.
- Bybit position timestamp unit inconsistency: WS path uses `updated_time * 1_000_000` (ms->ns), but REST path publishes `exch_ts: position.updated_time` without scaling. See `connector/src/bybit/private_stream.rs:174` vs `connector/src/bybit/private_stream.rs:386`.
- Binance Spot depth snapshot uses `last_update_id` (a sequence ID) as `exch_ts` by multiplying by 1_000_000. This is not a timestamp and can corrupt downstream ordering/fusion logic. See `connector/src/binancespot/market_data_stream.rs:198` and `connector/src/binancespot/market_data_stream.rs:216`.
- Binance spot/futures depth sync algorithm is incomplete/incorrect for reliable books: it fetches a REST snapshot but does not buffer and replay WS depth updates around the snapshot; `pending_depth_messages` is effectively unused and the update-id continuity checks are commented out. This risks permanently desynced orderbooks under common conditions (packet loss/reorder). See `connector/src/binancespot/market_data_stream.rs:65` and `connector/src/binancefutures/market_data_stream.rs:65`.
- Binance status decoding is too strict: `from_str_to_status` rejects statuses like `REJECTED` and `EXPIRED_IN_MATCH`, causing serde decode failure and dropped order updates (stale state). See `connector/src/binancespot/msg/mod.rs:25` and `connector/src/binancefutures/msg/mod.rs:25`.
- Binance order type decoding is too strict: only `LIMIT`/`MARKET` accepted; WS can deliver `STOP`, `TAKE_PROFIT`, etc depending on account/order settings, causing dropped updates. See `connector/src/binancespot/msg/mod.rs:45` and `connector/src/binancefutures/msg/mod.rs:45`.
- Binance Spot REST depth endpoint likely wrong/outdated (`/api/v1/depth` vs commonly `/api/v3/depth`), risking hard failure for snapshots. See `connector/src/binancespot/rest.rs:155`.

Reconnect/keepalive resilience issues:
- “Ping timeout” logic updates `last_ping` only when a WS *Ping frame* is received, not when regular traffic arrives; if the server never sends ping frames (but does send data), the connection will be dropped after 300s despite being healthy. See `connector/src/binancespot/market_data_stream.rs:277` and `connector/src/binancefutures/market_data_stream.rs:277` (similar pattern in user streams: `connector/src/binancespot/user_data_stream.rs:169`, `connector/src/binancefutures/user_data_stream.rs:167`).
- Binance futures listenKey keepalive failures are logged but do not force reconnect; this can lead to silent listenKey expiration and stale private state. See `connector/src/binancefutures/user_data_stream.rs:160`.

Major REST signing bug (likely breaks authenticated REST calls):
- For Binance spot and futures, the signed payload concatenates `timestamp` and the body without an `&` separator (`...timestamp={time}{body}`), which is not a valid parameter string when `body` begins with `newClientOrderId=...` / `symbol=...`. This likely yields invalid signatures for POST/PUT/DELETE calls. See `connector/src/binancespot/rest.rs:87` / `connector/src/binancespot/rest.rs:111` / `connector/src/binancespot/rest.rs:135` and `connector/src/binancefutures/rest.rs:84` / `connector/src/binancefutures/rest.rs:108` / `connector/src/binancefutures/rest.rs:132`.

Security-ish / stability-hardening notes:
- Several subscribe messages are built via `format!("{ ... \"{symbol}...\" }")` without JSON escaping; a malformed symbol from upstream could produce invalid JSON or unintended subscription strings. Prefer building request structs and `serde_json::to_string`. Example: `connector/src/binancespot/market_data_stream.rs:286`.
- REST query/body strings are manually concatenated without URL encoding; unusual symbols/prefixes could break requests/signatures.

Suggested error-handling direction (no code changes made):
- Replace `unwrap()` on server-provided Option fields with explicit checks and structured errors; replace channel `.send(...).unwrap()` with `let _ = ...` + logging.
- Fix Bybit `exec_price_tick` computation to use `tick_size`.
- Fix timestamp unit consistency (ms->ns) across all position/order events.
- Fix Binance REST signature string construction (`...timestamp={time}&{body}` when body non-empty) and consider adding `Content-Type: application/x-www-form-urlencoded`.
- Expand Binance status/type/tif decoding to map unknowns to `Status::Unsupported`/`OrdType::Unsupported` instead of hard serde failure.
- Rework WS liveness detection: update last-seen on *any* message (Text/Pong) and/or send periodic Ping and require Pong.
- Implement correct depth snapshot+diff replay logic per Binance docs, or avoid publishing depth until snapshot is established and update-ids are continuous.
~~~~

## agent_09_collector_file_io (status: needs_attention)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_09_collector_file_io/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_d08f712a/final.json`

~~~~text
Scope: collector/src/** (rotation, timestamping, throttling, exchange HTTP).

1) Panic / assumption risks (clock issues, API changes)
- collector/src/file.rs:39,46-49,55: multiple `unwrap()` on `self.file` (`take().unwrap()`, `as_mut().unwrap()`, `drop` uses `take().unwrap()`); if rotation happens and `create(...)` returns Err after `take()`, `self.file` becomes `None` and later `Drop` panics (and/or next `write` panics).
- collector/src/file.rs:45 and collector/src/throttler.rs:24: `timestamp_nanos_opt().unwrap()` can panic if system clock jumps to an out-of-range instant (or if a non-“now” datetime is ever passed in).
- collector/src/bybit/http.rs:81: `tx.send(()).unwrap()` will panic if the ping-task receiver is dropped (e.g., the task exits after a write error) while the read-loop later receives a Ping.
- collector/src/binance/http.rs:29-42, collector/src/binancefuturesum/http.rs:29-43, collector/src/binancefuturescm/http.rs:29-43: JSON shape assumptions via `.get(...).unwrap().as_array().unwrap().as_str().unwrap()`; any API error payload / schema change turns into a panic (these fns return `Result<_, reqwest::Error>` so panics bypass normal error handling).
- Soft data-loss (non-panic) risk: several handlers ignore unexpected message shapes by doing `if let Some(...) { ... }` without an `else` log/metric; under schema drift you can silently stop recording.

2) File-write atomicity / durability / corruption risks
- Severe corruption-on-restart: collector/src/file.rs:21-24 opens daily files with `.create(true).write(true).open(...)` but NOT `append(true)` or `truncate(true)`.
  - If `{path}_{date}.gz` already exists (restart, multiple runs), writes begin at offset 0 and overwrite the gzip header/first bytes, leaving the old tail in place → corrupted gzip + mixed/invalid stream.
- Crash/power-loss durability: no `flush()`/`sync_data()`/`sync_all()` strategy. Data can sit in (a) gzip encoder buffers and/or (b) OS page cache until rotation/drop; a crash can lose buffered data even on “graceful” shutdown without fsync.
- Partial gzip stream risk: streaming gzip means an unclean exit can leave an incomplete member; many decompressors treat this as an error (potentially losing more than the last record).
- Error suppression: collector/src/file.rs:40 and 55 ignore `finish()` results (`let _ = ...`), so I/O errors during finalization (disk full, ENOSPC, EIO) are silently swallowed; you may think you collected data but produced unreadable/cut files.
- Consumer-facing atomicity: writing directly to final `*.gz` means any concurrent reader can observe partial/in-progress gzip.

3) Concrete hardening suggestions
- Make restarts safe:
  - Open daily files in append mode (`.append(true)`) so you only add new gzip “members” to the end (valid gzip concatenation), OR use `.truncate(true)` if you intend “fresh file per run”.
  - Prefer writing to `*.gz.part` (or similar) and `rename()` to `*.gz` only after successful `finish()` at rotation/shutdown (atomic publish).
- Remove `unwrap()` panics in I/O paths:
  - Don’t `take()` until after successfully creating the new file; or keep the old encoder if the new one fails.
  - Make `Drop` resilient (`if let Some(f) = self.file.take() { ... }`) and log errors instead of panicking.
  - Replace `timestamp_nanos_opt().unwrap()` with an error return or fallback formatting.
- Add explicit durability knobs (configurable):
  - Periodically `encoder.flush()` and then `encoder.get_mut().sync_data()` (or `sync_all()`) every N records / seconds, plus always on rotation and on ctrl-c.
  - If fsync-per-record is too slow, expose an interval-based fsync policy; document expected loss window.
- Fix clock sensitivity in throttling:
  - Use `tokio::time::Instant` (monotonic) for the 60s window instead of `Utc::now()`; a backward wall-clock step currently can lock out snapshot fetches (throttle sees an ever-growing retained list).
- Harden exchange HTTP/JSON parsing:
  - Call `.error_for_status()?` before parsing.
  - Replace `.unwrap()` JSON navigation with typed `serde` structs or `get(...).and_then(...)` + explicit error (so API changes become logged errors/retries, not process abort).
- Avoid panic on Bybit ping:
  - Replace `tx.send(()).unwrap()` with `if tx.send(()).is_err() { /* connection is shutting down */ }` and let the outer loop reconnect.
- Backpressure / OOM avoidance:
  - Current unbounded channels (`unbounded_channel`) between websocket tasks and the writer can accumulate indefinitely if disk is slow → OOM → crash/data loss. Consider bounded channels + backpressure, or explicit drop-with-metrics policy.
- Connection retry backoff bug (data-loss via reconnect thrash):
  - In `keep_connection` for Binance* and Bybit, the `if error_count > 3 { ... } else if error_count > 10 { ... } else if error_count > 20 { ... }` ordering means you never hit the longer sleeps; reorder highest→lowest.
~~~~

## agent_10_derive_macro_safety (status: ok)

- final.json: `/Users/simongu/ParallelHassnes/runs/batch_20260120T084732Z_64624b39/agent_10_derive_macro_safety/steps/run/attempts/20260120T084733Z_run_20260120T084733Z_eee201b9/final.json`

~~~~text
Audited `hftbacktest-derive/src/lib.rs` for proc-macro robustness + generated-code risks.

1) Unwrap/panic that can break downstream builds (proc-macro panics / poor diagnostics)
- Proc-macro panic on unsupported field type in `NpyDTyped` derive: `panic!("... unsupported")` at `hftbacktest-derive/src/lib.rs:50`. Recommend: replace with `syn::Error::new_spanned(&field.ty, format!(...)).to_compile_error()`.
- Proc-macro panic on endianness “impossible” branch: `panic!()` at `hftbacktest-derive/src/lib.rs:89`. Recommend: remove this runtime probe entirely (see endianness note below).
- Proc-macro panic for unknown market depth in `build_asset`: `_ => panic!()` at `hftbacktest-derive/src/lib.rs:251`. Recommend: validate `marketdepth` once and return `syn::Error::new_spanned(&marketdepth, "unsupported market depth; expected ...")`.
- `unwrap()` used in proc-macro code path: `field.ident.as_ref().unwrap()` at `hftbacktest-derive/src/lib.rs:31` is logically safe due to `Fields::Named`, but still turns invariants into “proc macro panicked” if refactored later; recommend `ok_or_else(|| Error::new_spanned(field, "expected named field"))?`.
- Generated runtime `unwrap()`s in `build_asset` expansion (not compile-time panics, but still “generated code risk”): `build().unwrap()` at `hftbacktest-derive/src/lib.rs:267` and `hftbacktest-derive/src/lib.rs:274`, `read_npz_file(...).unwrap()` at `hftbacktest-derive/src/lib.rs:286` and `hftbacktest-derive/src/lib.rs:305`. Recommend: either propagate as `Result` from the surrounding API, or at least use `expect("...")` with actionable context; also avoid reading the same snapshot file twice (see below).

2) Generated code that may be unsound/surprising
- Cross-compilation endianness bug: `NpyDTyped` derives embed endianness at macro-expansion time (`is_little_endian()`), so host-endian is baked into the binary (`hftbacktest-derive/src/lib.rs:35`, `hftbacktest-derive/src/lib.rs:82`). For cross-compiles, proc-macro runs on host, but `descr()` is used on target → wrong dtype prefixes. Recommend: generate `descr()` code that chooses `"<"/">"` via `cfg!(target_endian = "little")` (evaluated for the compiled target), not via proc-macro runtime.
- Layout/padding/interop risk for `.npy`: `write_npy` writes raw bytes of `T` (`hftbacktest/src/backtest/data/npy/mod.rs:414`) but the derived `descr` only lists field names + scalar dtypes (no explicit `itemsize`/offsets/padding). Any padding in `#[repr(C)]` structs (or any `repr(Rust)` layout variability) can produce `.npy` files that are not correctly interpretable by NumPy, and may even disagree with the implied dtype itemsize. Recommend: at minimum require/validate `#[repr(C)]` in the derive (parse attrs) and generate a const-check like `const _: () = assert!(size_of::<Self>() == SUM_OF_FIELD_SIZES);` (or explicitly emit padding fields like `|Vn` if you want to support padded structs while staying NumPy-compatible).
- Fragile type detection: `let ty_str = quote!{#field_type}.to_string()` then string-match against `"f64"`, `"half::f16"`-style types, etc. (`hftbacktest-derive/src/lib.rs:34-51`). This is brittle across paths (`::core::primitive::f64`), type aliases, and imports. Recommend: match on `syn::Type` (e.g., `Type::Path` last segment ident) and optionally support known paths (e.g., `half::f16`).
- Derive hygiene/portability: `impl crate::backtest::data::NpyDTyped for #name` (`hftbacktest-derive/src/lib.rs:60`) hard-codes `crate::...` as the consuming crate. Since `hftbacktest-derive` is labeled “internal”, this may be intentional, but it will fail if the derive is ever used from a different crate; a common fix is `proc_macro_crate` to resolve the correct crate path.
- Generic structs: the derive ignores generics/where-clauses (uses only `#name`), which will break when deriving on `struct Foo<T> { ... }`. Recommend: use `input.generics.split_for_impl()`.
- `build_asset` macro hygiene fragility: expansion references many unqualified names (`Reader`, `DataSource`, `AssetType`, etc.) (`hftbacktest-derive/src/lib.rs:255+`). This is fine for “internal” use at a known call site, but surprising if reused elsewhere; consider qualifying with `crate::...` (call-site crate) or an explicit path.
- `build_asset` reads the same snapshot file twice when `initial_snapshot` is `File` (`hftbacktest-derive/src/lib.rs:285-288` and `hftbacktest-derive/src/lib.rs:304-307`), which is surprising (double IO / possible inconsistency if the file changes). Recommend: load once, reuse for both local/exchange depths.

3) Minimal compile-time tests (trybuild-style) suggestions
- Add `hftbacktest-derive/tests/trybuild.rs` with `trybuild::TestCases`.
- Suggested UI cases:
  - `tests/ui/npy_dtyped_ok.rs` (pass): `#[repr(C)] struct S { a: u64, b: i32, c: f64 }` + `unsafe impl POD for S {}` + `#[derive(NpyDTyped)]`.
  - `tests/ui/npy_dtyped_tuple_struct.rs` (fail): `struct S(u64); #[derive(NpyDTyped)]` should produce a `syn::Error` (“named fields required”) rather than silently generating an empty dtype.
  - `tests/ui/npy_dtyped_unsupported_type.rs` (fail): include `String`/`usize` field; assert error contains “unsupported field type”.
  - `tests/ui/npy_dtyped_generic.rs` (current fail; future pass after fix): `struct S<T>{ x: T }` to ensure generics are handled or rejected with a clear message.
  - `tests/ui/build_asset_unknown_marketdepth.rs` (fail): call `build_asset!(asset, UnknownMarketDepth, ...)` and assert it errors cleanly (not “proc macro panicked”).
  - Optional `tests/ui/build_asset_smoke.rs` (pass): minimal stubs in a module to ensure the macro’s required names are in scope and expansion typechecks.
~~~~
